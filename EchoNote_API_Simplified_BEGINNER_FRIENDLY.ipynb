{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ EchoNote API - Simplified Beginner-Friendly Version\n",
    "\n",
    "**Welcome!** This notebook creates an API for your AI meeting summarizer.\n",
    "\n",
    "## ğŸ“‹ What This Does:\n",
    "1. Loads your AI model from HuggingFace\n",
    "2. Creates a web server (API) that others can use\n",
    "3. Uses NGROK to give your server a public web address\n",
    "4. You can send meeting transcripts and get summaries back!\n",
    "\n",
    "## â±ï¸ Time Needed: 15-20 minutes\n",
    "\n",
    "## ğŸ“š Before You Start:\n",
    "1. Get NGROK auth token from: https://dashboard.ngrok.com/signup\n",
    "2. Make sure you're using **T4 GPU** (Runtime â†’ Change runtime type)\n",
    "3. Read `BEGINNERS_GUIDE.md` for detailed explanations\n",
    "\n",
    "## ğŸ¯ Quick Tips:\n",
    "- Run cells **in order** (don't skip any!)\n",
    "- Cell 3 takes **5-10 minutes** (downloading model)\n",
    "- If you see errors, check the troubleshooting guide\n",
    "\n",
    "Let's get started! ğŸ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“¦ STEP 1: Install Everything We Need\n",
    "\n",
    "**What this does:** Downloads and installs all the software libraries\n",
    "\n",
    "**Think of it like:** Installing apps on your phone before you can use them\n",
    "\n",
    "**Time:** ~2 minutes\n",
    "\n",
    "**What you'll see:** Installation messages (this is normal!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“¦ Installing required software...\")\n",
    "print(\"â±ï¸  This takes about 2 minutes. Please wait...\")\n",
    "\n",
    "# Install FastAPI (creates the web server)\n",
    "!pip install -q fastapi uvicorn python-multipart\n",
    "\n",
    "# Install NGROK (creates the public web address)\n",
    "!pip install -q pyngrok\n",
    "\n",
    "# Install Unsloth (makes AI model run 2x faster!)\n",
    "!pip install -q \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "\n",
    "# Install utilities\n",
    "!pip install -q slowapi tenacity\n",
    "\n",
    "print(\"âœ… All software installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# âš™ï¸ STEP 2: Your Settings (EDIT THIS PART!)\n",
    "\n",
    "**What this does:** This is where you put YOUR information\n",
    "\n",
    "**Think of it like:** Filling out a form with your personal details\n",
    "\n",
    "**Time:** ~2 minutes\n",
    "\n",
    "**âš ï¸ IMPORTANT:** You MUST edit this cell with your own values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nâš™ï¸ Loading your settings...\")\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# ğŸ”‘ YOUR NGROK TOKEN (REQUIRED!)\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Where to get it:\n#   1. Go to: https://dashboard.ngrok.com/get-started/your-authtoken\n#   2. Copy the long string of letters and numbers\n#   3. Paste it below between the quotes \"\"\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nNGROK_AUTH_TOKEN = \"YOUR_TOKEN_HERE\"  # â† PASTE YOUR TOKEN HERE!\n\n# Example (yours will be different):\n# NGROK_AUTH_TOKEN = \"2aB3cD4eF5gH6iJ7kL8mN9oP0qR1sT2u\"\n\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# ğŸŒ STATIC DOMAIN (OPTIONAL - But recommended!)\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# A static domain means you get the SAME web address every time!\n# Without it, you get a new random address each time.\n#\n# To get a free static domain:\n#   1. Go to: https://dashboard.ngrok.com/cloud-edge/domains\n#   2. Click \"New Domain\"\n#   3. Choose a name like \"echonote-api\"\n#   4. You'll get: echonote-api.ngrok-free.app\n#   5. Paste it below (or leave as None)\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nNGROK_STATIC_DOMAIN = None  # â† Change to your domain if you have one\n\n# Example:\n# NGROK_STATIC_DOMAIN = \"echonote-api.ngrok-free.app\"\n\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# ğŸ” YOUR API KEY (MUST MATCH BACKEND!)\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# This is like a password for your API\n# IMPORTANT: This MUST match backend/.env file!\n# Backend expects: CUSTOM_MODEL_API_KEY=echonote-secret-api-key-2025\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nAPI_KEY = \"echonote-secret-api-key-2025\"  # â† Matches backend .env\n\n# âš ï¸ WARNING: Anyone who knows this key can use your API!\n# Keep it secret and change it in production!\n\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# ğŸ¤– MODEL SETTINGS (Usually don't need to change)\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nMODEL_NAME = \"haris936hk/echonote\"  # Your fine-tuned model\nMAX_SEQ_LENGTH = 4096  # Maximum text length\nLOAD_IN_4BIT = True  # Use 4-bit to save memory (recommended!)\n\n# Server settings\nHOST = \"0.0.0.0\"  # Don't change this\nPORT = 8000  # Don't change this\nRATE_LIMIT = \"10/minute\"  # Max 10 requests per minute\n\n# Inference settings\nMAX_NEW_TOKENS = 1000  # Maximum length of summary\nTEMPERATURE = 0.3  # How creative (0.1=focused, 1.0=creative)\nREQUEST_TIMEOUT = 60  # Seconds to wait before timeout\n\nprint(\"âœ… Settings loaded!\")\nprint(f\"   Model: {MODEL_NAME}\")\nprint(f\"   API Key: {'*' * (len(API_KEY) - 4) + API_KEY[-4:] if len(API_KEY) > 4 else '****'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ¤– STEP 3: Load the AI Model\n",
    "\n",
    "**What this does:** Downloads your AI model from HuggingFace\n",
    "\n",
    "**Think of it like:** Downloading a big app (7GB!)\n",
    "\n",
    "**Time:** ~5-10 minutes (first time only)\n",
    "\n",
    "**â±ï¸ BE PATIENT:** First time is slow, but next time is faster (it's cached)\n",
    "\n",
    "**What you'll see:** Download progress bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ¤– Loading AI model from HuggingFace...\")\n",
    "print(\"â±ï¸  First time: 5-10 minutes (downloading 7GB)\")\n",
    "print(\"â±ï¸  Next time: Much faster! (already downloaded)\")\n",
    "print(\"ğŸ”„ Please wait...\")\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "\n",
    "# Load the model\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=MODEL_NAME,  # Your model\n",
    "    max_seq_length=MAX_SEQ_LENGTH,  # Max text length\n",
    "    dtype=None,  # Auto-detect best type\n",
    "    load_in_4bit=LOAD_IN_4BIT,  # Save memory\n",
    ")\n",
    "\n",
    "# Enable fast inference (makes it 2x faster!)\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "print(\"âœ… Model loaded successfully!\")\n",
    "print(\"   The AI is ready to summarize meetings!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ”§ STEP 4: Create the AI Processing Function\n",
    "\n",
    "**What this does:** Creates the function that runs the AI\n",
    "\n",
    "**Think of it like:** Teaching the AI how to process your requests\n",
    "\n",
    "**Time:** Instant!\n",
    "\n",
    "**What you'll see:** Function definition (no output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ”§ Setting up AI processing function...\")\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "# The instructions we give to the AI\n",
    "SYSTEM_PROMPT = \"\"\"You are an AI assistant that summarizes meeting transcripts.\n",
    "\n",
    "Please read the transcript and create a structured JSON summary with:\n",
    "- executiveSummary: A brief 60-100 word overview\n",
    "- keyDecisions: List of important decisions made\n",
    "- actionItems: Tasks with assignee, deadline, and priority\n",
    "- nextSteps: What happens next\n",
    "- keyTopics: Main topics discussed\n",
    "- sentiment: Overall mood (positive/neutral/negative)\n",
    "\n",
    "Output ONLY valid JSON, nothing else.\"\"\"\n",
    "\n",
    "# Function that runs the AI\n",
    "@retry(\n",
    "    stop=stop_after_attempt(3),  # Try 3 times if it fails\n",
    "    wait=wait_exponential(multiplier=1, min=2, max=10)\n",
    ")\n",
    "def generate_summary(transcript: str) -> str:\n",
    "    \"\"\"\n",
    "    Send transcript to AI and get summary back\n",
    "    \n",
    "    Input: Meeting transcript (text)\n",
    "    Output: JSON summary\n",
    "    \"\"\"\n",
    "    # Create the conversation\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": transcript}\n",
    "    ]\n",
    "    \n",
    "    # Format it for the model\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # Convert text to numbers (tokens)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Run the AI! âœ¨\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():  # Don't track gradients (saves memory)\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=MAX_NEW_TOKENS,\n",
    "            temperature=TEMPERATURE,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    \n",
    "    # Convert numbers back to text\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract just the JSON part\n",
    "    if \"<|im_start|>assistant\" in generated_text:\n",
    "        json_output = generated_text.split(\"<|im_start|>assistant\")[-1].strip()\n",
    "    else:\n",
    "        json_output = generated_text.split(prompt)[-1].strip()\n",
    "    \n",
    "    # Remove markdown if present\n",
    "    json_output = json_output.replace('```json', '').replace('```', '').strip()\n",
    "    \n",
    "    inference_time = time.time() - start_time\n",
    "    print(f\"âœ… AI processed in {inference_time:.2f} seconds\")\n",
    "    \n",
    "    return json_output\n",
    "\n",
    "print(\"âœ… AI processing function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸŒ STEP 5: Create the Web Server (API)\n",
    "\n",
    "**What this does:** Creates a web server that accepts requests\n",
    "\n",
    "**Think of it like:** Opening a restaurant where people can order food\n",
    "\n",
    "**Time:** Instant!\n",
    "\n",
    "**What you'll see:** API setup confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nğŸŒ Creating web server (API)...\")\n\nfrom fastapi import FastAPI, HTTPException, Security, Request\nfrom fastapi.security import APIKeyHeader\nfrom fastapi.responses import JSONResponse\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom pydantic import BaseModel, Field\nfrom typing import Optional, Dict, Any\nfrom slowapi import Limiter, _rate_limit_exceeded_handler\nfrom slowapi.util import get_remote_address\nfrom slowapi.errors import RateLimitExceeded\nfrom datetime import datetime\nimport json\nimport asyncio\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Define what input we accept\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\nclass MeetingInput(BaseModel):\n    \"\"\"What we expect from user: a transcript\"\"\"\n    transcript: str = Field(\n        ...,\n        min_length=100,\n        max_length=15000,  # â† Increased to handle NLP-enhanced transcripts!\n        description=\"Meeting transcript (100-15000 characters)\"\n    )\n\nclass SummaryOutput(BaseModel):\n    \"\"\"What we send back: summary + metadata\"\"\"\n    summary: Dict[str, Any]\n    metadata: Dict[str, Any]\n\nclass HealthResponse(BaseModel):\n    \"\"\"Health check response\"\"\"\n    status: str\n    model: str\n    timestamp: str\n    uptime_seconds: float\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Create the FastAPI app\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\napp = FastAPI(\n    title=\"EchoNote API - Beginner Friendly\",\n    description=\"AI-powered meeting summarization API\",\n    version=\"1.0.0\",\n    docs_url=\"/docs\",  # Swagger UI at /docs\n)\n\n# Allow requests from anywhere\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Add rate limiting\nlimiter = Limiter(key_func=get_remote_address)\napp.state.limiter = limiter\napp.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)\n\n# API key security\napi_key_header = APIKeyHeader(name=\"X-API-Key\", auto_error=False)\n\ndef verify_api_key(api_key: Optional[str] = Security(api_key_header)):\n    \"\"\"Check if API key is correct\"\"\"\n    if api_key is None or api_key != API_KEY:\n        raise HTTPException(\n            status_code=403,\n            detail=\"Invalid API key! Include 'X-API-Key' header.\"\n        )\n    return api_key\n\n# Track when server started\nSERVER_START_TIME = time.time()\n\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n# Define the endpoints (routes)\n# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n\n@app.get(\"/\")\nasync def root():\n    \"\"\"Welcome message\"\"\"\n    return {\n        \"message\": \"Welcome to EchoNote API! ğŸ‰\",\n        \"model\": MODEL_NAME,\n        \"docs\": \"/docs - Interactive API documentation\",\n        \"health\": \"/health - Check if server is healthy\",\n        \"predict\": \"POST /predict - Get meeting summary\"\n    }\n\n@app.get(\"/health\", response_model=HealthResponse)\nasync def health_check():\n    \"\"\"Check if server is running\"\"\"\n    return HealthResponse(\n        status=\"healthy\",\n        model=MODEL_NAME,\n        timestamp=datetime.now().isoformat(),\n        uptime_seconds=time.time() - SERVER_START_TIME\n    )\n\n@app.post(\"/predict\", response_model=SummaryOutput)\n@limiter.limit(RATE_LIMIT)\nasync def predict(\n    request: Request,\n    meeting_input: MeetingInput,\n    api_key: str = Security(verify_api_key)\n):\n    \"\"\"\n    ğŸ¯ MAIN ENDPOINT: Send transcript, get summary!\n    \n    How to use:\n    1. Send POST request to /predict\n    2. Include header: X-API-Key: your-api-key\n    3. Send JSON: {\"transcript\": \"your meeting text...\"}\n    4. Get back: JSON summary with decisions, actions, etc.\n    \"\"\"\n    try:\n        start_time = time.time()\n        \n        # Run AI with timeout\n        try:\n            summary_json = await asyncio.wait_for(\n                asyncio.to_thread(generate_summary, meeting_input.transcript),\n                timeout=REQUEST_TIMEOUT\n            )\n        except asyncio.TimeoutError:\n            raise HTTPException(\n                status_code=504,\n                detail=f\"Timeout after {REQUEST_TIMEOUT} seconds\"\n            )\n        \n        # Parse JSON\n        try:\n            summary_dict = json.loads(summary_json)\n        except json.JSONDecodeError:\n            raise HTTPException(\n                status_code=500,\n                detail=\"AI output was not valid JSON\"\n            )\n        \n        # Calculate time taken\n        inference_time = time.time() - start_time\n        \n        # Return response\n        return SummaryOutput(\n            summary=summary_dict,\n            metadata={\n                \"model\": MODEL_NAME,\n                \"inference_time_seconds\": round(inference_time, 2),\n                \"timestamp\": datetime.now().isoformat(),\n                \"transcript_length\": len(meeting_input.transcript),\n            }\n        )\n        \n    except HTTPException:\n        raise\n    except Exception as e:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Error: {str(e)}\"\n        )\n\nprint(\"âœ… Web server (API) created!\")\nprint(\"   Endpoints: /, /health, /predict, /docs\")\nprint(\"   Max transcript length: 15000 characters (handles NLP enhancements)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸŒ‰ STEP 6: Create NGROK Tunnel\n",
    "\n",
    "**What this does:** Creates a public URL so anyone can access your API\n",
    "\n",
    "**Think of it like:** Getting a phone number so people can call you\n",
    "\n",
    "**Time:** Instant!\n",
    "\n",
    "**âš ï¸ IMPORTANT:** Copy the Public URL from the output - you'll need it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nğŸŒ‰ Creating NGROK tunnel (public web address)...\")\n\nfrom pyngrok import ngrok\nimport nest_asyncio\n\n# Allow nested event loops\nnest_asyncio.apply()\n\n# Set your auth token\nif NGROK_AUTH_TOKEN and NGROK_AUTH_TOKEN != \"YOUR_TOKEN_HERE\":\n    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n    print(\"âœ… NGROK auth token set\")\nelse:\n    print(\"âŒ ERROR: You need to set your NGROK_AUTH_TOKEN!\")\n    print(\"   Get it from: https://dashboard.ngrok.com/get-started/your-authtoken\")\n    print(\"   Then edit Step 2 above\")\n    raise ValueError(\"NGROK_AUTH_TOKEN not configured\")\n\n# Close any existing tunnels\nngrok.kill()\n\n# Create the tunnel\nif NGROK_STATIC_DOMAIN:\n    # Use your static domain\n    print(f\"ğŸ”— Using static domain: {NGROK_STATIC_DOMAIN}\")\n    public_url = ngrok.connect(PORT, domain=NGROK_STATIC_DOMAIN, bind_tls=True)\nelse:\n    # Use random domain\n    print(\"ğŸ”— Using random domain (changes each time)\")\n    public_url = ngrok.connect(PORT, bind_tls=True)\n\n# Save the URL\nNGROK_PUBLIC_URL = str(public_url)\n\n# Display success message\nprint(\"\\n\" + \"=\"*80)\nprint(\"ğŸ‰ SUCCESS! YOUR API IS READY!\")\nprint(\"=\"*80)\nprint(f\"\\nğŸŒ Your Public URL: {NGROK_PUBLIC_URL}\")\nprint(f\"\\nğŸ“š Test it here: {NGROK_PUBLIC_URL}/docs\")\nprint(f\"â¤ï¸ Health check: {NGROK_PUBLIC_URL}/health\")\nprint(f\"\\nğŸ”‘ Your API Key: {API_KEY}\")\n\n# âš ï¸ IMPORTANT: Backend configuration instructions\nprint(\"\\n\" + \"=\"*80)\nprint(\"âš ï¸  IMPORTANT: UPDATE YOUR BACKEND .ENV FILE!\")\nprint(\"=\"*80)\nprint(\"\\nğŸ“ Follow these steps to connect your webapp:\")\nprint(f\"\\n  1. Open: backend/.env (or backend/.env.example)\")\nprint(f\"\\n  2. Update this line:\")\nprint(f\"     CUSTOM_MODEL_API_URL={NGROK_PUBLIC_URL}\")\nprint(f\"\\n  3. Verify API key matches:\")\nprint(f\"     CUSTOM_MODEL_API_KEY={API_KEY}\")\nprint(f\"\\n  4. Save the file and restart your backend:\")\nprint(f\"     cd backend\")\nprint(f\"     npm run dev\")\nprint(f\"\\n  5. Your webapp can now generate AI summaries! âœ…\")\nprint(\"\\n\" + \"=\"*80)\n\nprint(\"\\nğŸ’¡ NEXT STEPS:\")\nprint(\"   1. Run the next cell to start the server\")\nprint(\"   2. Update backend/.env as shown above\")\nprint(\"   3. Restart backend server\")\nprint(\"   4. Upload a meeting via your webapp\")\nprint(\"   5. Watch the magic happen! ğŸ‰\")\nprint(\"=\"*80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸš€ STEP 7: Start the Server\n",
    "\n",
    "**What this does:** Starts the web server in the background\n",
    "\n",
    "**Think of it like:** Opening your restaurant for business\n",
    "\n",
    "**Time:** Instant! (server runs in background)\n",
    "\n",
    "**âœ… FIXED:** This version works in Jupyter notebooks (no event loop errors!)\n",
    "\n",
    "**Note:** Server keeps running - you can continue using other cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸš€ Starting the server...\")\n",
    "\n",
    "import uvicorn\n",
    "import threading\n",
    "\n",
    "# Configure uvicorn\n",
    "config = uvicorn.Config(\n",
    "    app=app,\n",
    "    host=HOST,\n",
    "    port=PORT,\n",
    "    log_level=\"info\",\n",
    "    access_log=True,\n",
    "    loop=\"asyncio\"\n",
    ")\n",
    "\n",
    "# Create server\n",
    "server = uvicorn.Server(config)\n",
    "\n",
    "# Function to run in thread\n",
    "def run_server():\n",
    "    \"\"\"Run server in background thread\"\"\"\n",
    "    import asyncio\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "    try:\n",
    "        loop.run_until_complete(server.serve())\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Server error: {e}\")\n",
    "    finally:\n",
    "        loop.close()\n",
    "\n",
    "# Start server in background\n",
    "server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "# Wait for startup\n",
    "time.sleep(3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… SERVER IS RUNNING! ğŸ‰\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nğŸŒ Your API is live at: {NGROK_PUBLIC_URL}\")\n",
    "print(f\"\\nğŸ“ TO TEST YOUR API:\")\n",
    "print(f\"   1. Open: {NGROK_PUBLIC_URL}/docs\")\n",
    "print(f\"   2. Click the green 'Authorize' button\")\n",
    "print(f\"   3. Enter API key: {API_KEY}\")\n",
    "print(f\"   4. Try the POST /predict endpoint\")\n",
    "print(f\"\\nâ¹ï¸ TO STOP SERVER:\")\n",
    "print(f\"   Run the cell below labeled 'STOP SERVER'\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# â¹ï¸ STEP 8: Stop Server (Run This When Done)\n",
    "\n",
    "**What this does:** Stops the server and closes NGROK\n",
    "\n",
    "**Think of it like:** Closing your restaurant at end of day\n",
    "\n",
    "**When to use:** When you're done using the API and want to shut everything down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ›‘ Stopping server...\")\n",
    "\n",
    "if 'server' in globals():\n",
    "    server.should_exit = True\n",
    "    print(\"âœ… Server shutdown signal sent\")\n",
    "    time.sleep(2)\n",
    "\n",
    "try:\n",
    "    ngrok.kill()\n",
    "    print(\"âœ… NGROK tunnel closed\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"\\nâœ… Everything stopped!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ‰ Congratulations! You're Done!\n",
    "\n",
    "Your API is now running and accessible from anywhere in the world!\n",
    "\n",
    "## ğŸ¯ What You Can Do Now:\n",
    "\n",
    "### 1. Test in Browser (Easiest!)\n",
    "- Go to: `{YOUR_URL}/docs`\n",
    "- Click \"Authorize\" â†’ Enter your API key\n",
    "- Try the POST /predict endpoint\n",
    "- Send a meeting transcript and get a summary!\n",
    "\n",
    "### 2. Test from Python (On Your Laptop)\n",
    "Use the `test_echonote_api.py` script provided:\n",
    "```python\n",
    "python test_echonote_api.py\n",
    "```\n",
    "\n",
    "### 3. Call from Your Own Code\n",
    "See the example below!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ Example Code to Call Your API\n",
    "\n",
    "Run this on YOUR LAPTOP (not in this notebook):\n",
    "\n",
    "```python\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Your API details (from above)\n",
    "NGROK_URL = \"YOUR_URL_HERE\"  # From Step 6 output\n",
    "API_KEY = \"YOUR_API_KEY\"     # From Step 2\n",
    "\n",
    "# Test the API\n",
    "response = requests.post(\n",
    "    f\"{NGROK_URL}/predict\",\n",
    "    json={\n",
    "        \"transcript\": \"Meeting about Q3 goals. Sarah to deliver report by Friday.\"\n",
    "    },\n",
    "    headers={\n",
    "        \"X-API-Key\": API_KEY,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"ngrok-skip-browser-warning\": \"true\"\n",
    "    }\n",
    ")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    print(\"âœ… Success!\")\n",
    "    print(json.dumps(result['summary'], indent=2))\n",
    "else:\n",
    "    print(f\"âŒ Error: {response.status_code}\")\n",
    "    print(response.text)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ†˜ Need Help?\n",
    "\n",
    "Check the full guides:\n",
    "- `BEGINNERS_GUIDE.md` - Complete tutorial with troubleshooting\n",
    "- `README_START_HERE.md` - Overview of all files\n",
    "- `QUICK_START_CHECKLIST.md` - Step-by-step checklist\n",
    "\n",
    "### Common Issues:\n",
    "- **\"Invalid API key\"** â†’ Make sure API key matches in both places\n",
    "- **\"Connection refused\"** â†’ Make sure this notebook is still running\n",
    "- **\"429 Rate limit\"** â†’ Wait 60 seconds between requests\n",
    "- **Model loading slow** â†’ Normal! First time takes 5-10 minutes\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“ What You Learned:\n",
    "\n",
    "âœ… How to deploy AI models to the cloud\n",
    "âœ… How to create APIs with FastAPI\n",
    "âœ… How to use NGROK for public access\n",
    "âœ… How to test APIs (browser & Python)\n",
    "âœ… How to work with Jupyter notebooks\n",
    "\n",
    "---\n",
    "\n",
    "**ğŸ‰ Great job! You've deployed your first AI API!**\n",
    "\n",
    "*Now go build something amazing with it! ğŸš€*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}